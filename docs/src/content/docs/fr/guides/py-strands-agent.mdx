---
title: "Agent de Strands Python"
description: "Générer un Agent de Strands Python pour construire des agents IA avec des outils et déployer sur Amazon Bedrock AgentCore Runtime"
---

import { FileTree } from '@astrojs/starlight/components';
import RunGenerator from '@components/run-generator.astro';
import NxCommands from '@components/nx-commands.astro';
import Link from '@components/link.astro';
import Snippet from '@components/snippet.astro';
import Infrastructure from '@components/infrastructure.astro';
import GeneratorParameters from '@components/generator-parameters.astro';
import Drawer from '@components/drawer.astro';

Générer un agent [Strands Agent](https://strandsagents.com/) en Python pour créer des agents IA avec des outils, et optionnellement le déployer sur [Amazon Bedrock AgentCore Runtime](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/).

## Qu'est-ce que Strands ?

[Strands](https://strandsagents.com/latest/documentation/docs/) est un framework Python léger et prêt pour la production permettant de créer des agents IA. Principales fonctionnalités :

- **Léger et personnalisable** : Boucle d'agent simple qui reste discrète
- **Prêt pour la production** : Observabilité complète, traçage et options de déploiement évolutives
- **Agnostique aux modèles et fournisseurs** : Supporte de nombreux modèles de différents fournisseurs
- **Outils communautaires** : Ensemble puissant d'outils contribués par la communauté
- **Support multi-agents** : Techniques avancées comme les équipes d'agents et agents autonomes
- **Modes d'interaction flexibles** : Support conversationnel, streaming et non-streaming

## Utilisation

### Générer un agent Strands

Vous pouvez générer un agent Strands en Python de deux manières :

<RunGenerator generator="py#strands-agent" />

:::tip
Utilisez d'abord le générateur <Link path="/guides/python-project">`py#project`</Link> pour créer un projet auquel ajouter votre agent Strands.
:::

### Options

<GeneratorParameters generator="py#strands-agent" />

## Résultat du générateur

Le générateur ajoutera les fichiers suivants à votre projet Python existant :

<FileTree>
  - your-project/
    - your_module/
      - agent/ (ou nom personnalisé si spécifié)
        - \_\_init\_\_.py Initialisation du package Python
        - agent.py Définition principale de l'agent avec des outils exemples
        - main.py Point d'entrée pour Bedrock AgentCore Runtime
        - agentcore_mcp_client.py Factory client utile pour invoquer des serveurs MCP hébergés sur Bedrock AgentCore Runtime
        - Dockerfile Point d'entrée pour héberger votre agent (exclu si `computeType` est `None`)
    - pyproject.toml Mis à jour avec les dépendances Strands
    - project.json Mis à jour avec les cibles de service de l'agent
</FileTree>

### Infrastructure

:::note
Si vous avez sélectionné `None` pour `computeType`, le générateur ne générera pas d'infrastructure as code.
:::

<Snippet name="shared-constructs" />

Pour le déploiement de votre agent Strands, les fichiers suivants sont générés :

<Infrastructure>
<Fragment slot="cdk">
<FileTree>
  - packages/common/constructs/src
    - app
      - agents
        - \<project-name>
          - \<project-name>.ts Construct CDK pour déployer votre agent
          - Dockerfile Fichier Docker transmis utilisé par le construct CDK
</FileTree>
</Fragment>
<Fragment slot="terraform">
<FileTree>
  - packages/common/terraform/src
    - app
      - agents
        - \<project-name>
          - \<project-name>.tf Module pour déployer votre agent
    - core
      - agent-core
        - runtime.tf Module générique pour le déploiement sur Bedrock AgentCore Runtime
</FileTree>
</Fragment>
</Infrastructure>

## Utilisation de votre agent Strands

### Ajout d'outils

Les outils sont des fonctions que l'agent IA peut appeler pour effectuer des actions. Le framework Strands utilise une approche basée sur des décorateurs pour définir les outils.

Vous pouvez ajouter de nouveaux outils dans le fichier [`agent.py`](packages/nx-plugin/src/py/strands-agent/files/agent.py.template:6) :

```python
from strands import Agent, tool

@tool
def calculate_sum(numbers: list[int]) -> int:
    """Calcule la somme d'une liste de nombres"""
    return sum(numbers)

@tool
def get_weather(city: str) -> str:
    """Obtient les informations météo d'une ville"""
    # Votre intégration d'API météo ici
    return f"Météo à {city} : Ensoleillé, 25°C"

# Ajoutez les outils à votre agent
agent = Agent(
    system_prompt="Vous êtes un assistant utile avec accès à divers outils.",
    tools=[calculate_sum, get_weather],
)
```

Le framework Strands gère automatiquement :
- La validation des types via les annotations de type
- La génération de schémas JSON pour l'appel d'outils
- La gestion des erreurs et le formatage des réponses

### Utilisation d'outils pré-définis

Strands fournit une collection d'outils prêts à l'emploi via le package `strands-tools` :

```python
from strands_tools import current_time, http_request, file_read

agent = Agent(
    system_prompt="Vous êtes un assistant utile.",
    tools=[current_time, http_request, file_read],
)
```

### Configuration du modèle

Par défaut, les agents Strands utilisent Claude 4 Sonnet, mais vous pouvez personnaliser le fournisseur de modèle. Consultez la [documentation Strands sur les fournisseurs de modèles](https://strandsagents.com/latest/documentation/docs/user-guide/quickstart/#model-providers) pour les options de configuration :

```python
from strands import Agent
from strands.models import BedrockModel

# Créez un BedrockModel
bedrock_model = BedrockModel(
    model_id="anthropic.claude-sonnet-4-20250514-v1:0",
    region_name="us-west-2",
    temperature=0.3,
)

agent = Agent(model=bedrock_model)
```

### Utilisation des serveurs MCP

Vous pouvez [ajouter des outils depuis des serveurs MCP](https://strandsagents.com/latest/documentation/docs/user-guide/concepts/tools/mcp-tools/) à votre agent Strands.

Pour utiliser des serveurs MCP créés avec les générateurs <Link path="/guides/py-mcp-server">`py#mcp-server`</Link> ou <Link path="/guides/ts-mcp-server">`ts#mcp-server`</Link> (ou d'autres hébergés sur Bedrock AgentCore Runtime), une factory client est générée pour vous dans `agentcore_mcp_client.py`.

Vous pouvez mettre à jour votre méthode `get_agent` dans `agent.py` pour créer des clients MCP et ajouter des outils. L'exemple suivant montre comment faire cela avec l'authentification IAM (SigV4) :

```python
# agent.py
import os
from contextlib import contextmanager

import boto3
from strands import Agent

from .agentcore_mcp_client import AgentCoreMCPClient

# Obtenez la région et les credentials
region = os.environ["AWS_REGION"]
boto_session = boto3.Session(region_name=region)
credentials = boto_session.get_credentials()

@contextmanager
def get_agent(session_id: str):
    mcp_client = AgentCoreMCPClient.with_iam_auth(
        agent_runtime_arn=os.environ["MCP_AGENTCORE_RUNTIME_ARN"],
        credentials=credentials,
        region=region,
        session_id=session_id,
    )

    with mcp_client:
        mcp_tools = mcp_client.list_tools_sync()

        yield Agent(
            system_prompt="..."
            tools=[*mcp_tools],
        )
```

:::tip
Si votre serveur MCP cible utilise l'authentification JWT, vous pouvez utiliser la méthode `AgentCoreMCPClient.with_jwt_auth` à la place.
:::

Avec l'exemple d'authentification IAM ci-dessus, nous devons configurer deux éléments dans notre infrastructure. Premièrement, ajouter la variable d'environnement consommée par notre agent pour l'ARN du runtime AgentCore du serveur MCP, et deuxièmement accorder les permissions d'invocation à notre agent. Cela peut être réalisé comme suit :

<Infrastructure>
<Fragment slot="cdk">
```ts {9, 13}
import { MyProjectAgent, MyProjectMcpServer } from ':my-scope/common-constructs';

export class ExampleStack extends Stack {
  constructor(scope: Construct, id: string) {
    const mcpServer = new MyProjectMcpServer(this, 'MyProjectMcpServer');

    const agent = new MyProjectAgent(this, 'MyProjectAgent', {
      environmentVariables: {
        MCP_AGENTCORE_RUNTIME_ARN: mcpServer.agentCoreRuntime.agentRuntimeArn,
      },
    });

    mcpServer.agentCoreRuntime.grantInvoke(agent.agentCoreRuntime);
  }
}
```
</Fragment>
<Fragment slot="terraform">
```terraform
# Serveur MCP
module "my_project_mcp_server" {
  source = "../../common/terraform/src/app/mcp-servers/my-project-mcp-server"
}

# Agent
module "my_project_agent" {
  source = "../../common/terraform/src/app/agents/my-project-agent"

  env = {
    MCP_AGENTCORE_RUNTIME_ARN = module.my_project_mcp_server.agent_core_runtime_arn
  }

  additional_iam_policy_statements = [
    {
      Effect = "Allow"
      Action = [
        "bedrock-agentcore:InvokeAgentRuntime"
      ]
      Resource = [
        module.my_project_mcp_server.agent_core_runtime_arn,
        "${module.my_project_mcp_server.agent_core_runtime_arn}/*"
      ]
    }
  ]
}
```
</Fragment>
</Infrastructure>

### Pour aller plus loin

Pour un guide plus détaillé sur l'écriture d'agents Strands, consultez la [documentation Strands](https://strandsagents.com/latest/documentation/docs/).

## Serveur FastAPI

Le générateur utilise [FastAPI](https://fastapi.tiangolo.com/) pour créer le serveur HTTP de votre agent Strands. FastAPI fournit un framework web moderne et rapide pour créer des API avec Python, avec documentation API automatique et validation de types.

Le serveur généré inclut :
- Configuration de l'application FastAPI avec middleware CORS
- Middleware de gestion des erreurs
- Génération du schéma OpenAPI
- Point de terminaison de vérification de santé (`/ping`)
- Point de terminaison d'invocation de l'agent (`/invocations`)

### Personnalisation des entrées et sorties d'invocation avec Pydantic

Le point de terminaison d'invocation de l'agent utilise des modèles [Pydantic](https://docs.pydantic.dev/) pour définir et valider les schémas de requête et de réponse. Vous pouvez personnaliser ces modèles dans `main.py` pour correspondre aux besoins de votre agent.

#### Définition des modèles d'entrée

Le modèle `InvokeInput` par défaut accepte un prompt et un ID de session.

```python
from pydantic import BaseModel

class InvokeInput(BaseModel):
    prompt: str
    session_id: str
```

Vous pouvez étendre ce modèle pour inclure tous les champs supplémentaires dont votre agent a besoin.

:::caution
Vous voudrez probablement abstraire tout ou partie de l'ID de session de l'appelant si les utilisateurs doivent invoquer votre agent directement. Par exemple, vous pouvez utiliser l'ID utilisateur authentifié comme partie de l'ID de session.

Il est également à noter que selon votre cas d'usage, vous devrez peut-être implémenter une autorisation pour les sessions, par exemple en vous assurant que les utilisateurs ne peuvent accéder qu'à leurs propres sessions et non à celles d'autres utilisateurs.
:::

#### Définition des modèles de sortie

Pour les réponses en streaming, l'annotation de type de retour sur votre point de terminaison correspond au type de chaque valeur générée par votre fonction génératrice. Par défaut, l'agent génère des chaînes contenant le texte de réponse de l'agent tel qu'il est diffusé en continu depuis Strands :

```python
@app.post("/invocations", openapi_extra={"x-streaming": True})
async def invoke(input: InvokeInput) -> str:
    """Point d'entrée pour l'invocation de l'agent"""
    return StreamingResponse(handle_invoke(input), media_type="text/event-stream")
```

Vous pouvez définir un modèle Pydantic pour générer des données structurées à la place. Pour ce faire, vous devrez sérialiser les modèles pydantic générés par `handle_invoke` :

```python
from pydantic import BaseModel

class StreamChunk(BaseModel):
    content: str
    timestamp: str
    token_count: int

def handle_invoke(...):
    ...
    yield StreamChunk(content="xx", timestamp="yy", token_count=5)

def serialize_stream(generator):
    async for output in generator:
        yield (output.model_dump_json() + "\n").encode("utf-8")

@app.post("/invocations", openapi_extra={"x-streaming": True})
async def invoke(input: InvokeInput) -> StreamChunk:
    return StreamingResponse(serialize_stream(handle_invoke(input)), media_type="application/json")
```

:::caution
Notez ici que le serveur fourni (et la méthode `serialize_stream` ci-dessus) ne se conforme pas actuellement au standard Server-Sent Events (SSE), de sorte que si vous le souhaitez, l'agent peut être invoqué par notre client TypeScript généré depuis un frontend, qui ne s'attend pas actuellement à des événements de streaming au format SSE. Veuillez mettre un +1 sur [ce problème GitHub](https://github.com/awslabs/nx-plugin-for-aws/issues/369) si cela vous affecte pour nous aider à prioriser la résolution de ce point.
:::

## SDK Python Bedrock AgentCore

Le générateur inclut une dépendance au [SDK Python Bedrock AgentCore](https://github.com/aws/bedrock-agentcore-sdk-python) pour les constantes `PingStatus`. Si vous le souhaitez, il est simple d'utiliser `BedrockAgentCoreApp` au lieu de FastAPI, mais notez que la sécurité des types est perdue.

Vous trouverez plus de détails sur les capacités du SDK dans la [documentation ici](https://aws.github.io/bedrock-agentcore-starter-toolkit/user-guide/runtime/quickstart.html).

:::note
Le générateur fournissant une infrastructure CDK ou Terraform pour déployer votre agent, vous n'avez pas besoin d'utiliser le `bedrock-agentcore-starter-toolkit` mentionné dans la documentation.
:::

## Exécution de votre agent Strands

### Développement local

Le générateur configure une cible nommée `<your-agent-name>-serve` qui démarre votre agent Strands localement pour le développement et les tests.

<NxCommands commands={['run your-project:agent-serve']} />

Cette commande utilise `uv run` pour exécuter votre agent Strands via le [SDK Python Bedrock AgentCore](https://github.com/aws/bedrock-agentcore-sdk-python).

## Déploiement de votre agent Strands sur Bedrock AgentCore Runtime

<Snippet name="agent/bedrock-deployment" parentHeading="Déploiement de votre agent Strands sur Bedrock AgentCore Runtime" />

### Cibles Bundle et Docker

Pour construire votre agent Strands pour Bedrock AgentCore Runtime, une cible `bundle` est ajoutée à votre projet, qui :

- Exporte vos dépendances Python dans un fichier `requirements.txt` via `uv export`
- Installe les dépendances pour la plateforme cible (`aarch64-manylinux2014`) via `uv pip install`

Une cible `docker` spécifique à votre agent Strands est également ajoutée, qui :

- Construit une image Docker depuis le `Dockerfile` exécutant votre agent, conformément au [contrat runtime AgentCore](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/runtime-service-contract.html)

:::tip
L'image Docker est construite avec un tag (ex: `my-scope-my-project-agent:latest`), référencé par votre infrastructure CDK ou Terraform, permettant à votre `Dockerfile` d'être co-localisé avec votre projet d'agent Strands.
:::

### Authentification

#### IAM

Par défaut, votre agent Strands sera sécurisé via l'authentification IAM. Déployez-le simplement sans arguments :

<Infrastructure>
<Fragment slot="cdk">
```ts {5}
import { MyProjectAgent } from ':my-scope/common-constructs';

export class ExampleStack extends Stack {
  constructor(scope: Construct, id: string) {
    new MyProjectAgent(this, 'MyProjectAgent');
  }
}
```

Vous pouvez accorder l'accès à votre agent sur Bedrock AgentCore Runtime via la méthode `grantInvoke`, par exemple :

```ts {8}
import { MyProjectAgent } from ':my-scope/common-constructs';

export class ExampleStack extends Stack {
  constructor(scope: Construct, id: string) {
    const agent = new MyProjectAgent(this, 'MyProjectAgent');
    const lambdaFunction = new Function(this, ...);

    agent.agentCoreRuntime.grantInvoke(lambdaFunction);
  }
}
```
</Fragment>
<Fragment slot="terraform">
```terraform
# Agent
module "my_project_agent" {
  # Chemin relatif vers le module généré dans le projet common/terraform
  source = "../../common/terraform/src/app/agents/my-project-agent"
}
```

Pour accorder l'accès à votre agent, ajoutez une politique IAM référençant la sortie `module.my_project_agent.agent_core_runtime_arn` :

```terraform
{
  Effect = "Allow"
  Action = [
    "bedrock-agentcore:InvokeAgentRuntime"
  ]
  Resource = [
    module.my_project_agent.agent_core_runtime_arn,
    "${module.my_project_agent.agent_core_runtime_arn}/*"
  ]
}
```
</Fragment>
</Infrastructure>

#### Authentification Cognito JWT

L'exemple suivant montre comment configurer l'authentification Cognito pour votre agent.

<Infrastructure>
<Fragment slot="cdk">
Pour configurer l'authentification JWT avec Cognito, utilisez la méthode factory `RuntimeAuthorizerConfiguration.usingCognito()` :

```ts {13-16}
import { MyProjectAgent } from ':my-scope/common-constructs';
import { RuntimeAuthorizerConfiguration } from '@aws-cdk/aws-bedrock-agentcore-alpha';

export class ExampleStack extends Stack {
  constructor(scope: Construct, id: string) {
    const userPool = new UserPool(this, 'UserPool');
    const client = userPool.addClient('Client', {
      authFlows: {
        userPassword: true,
      },
    });

    new MyProjectAgent(this, 'MyProjectAgent', {
      authorizerConfiguration: RuntimeAuthorizerConfiguration.usingCognito(
        userPool,
        [client],
      ),
    });
  }
}
```

Alternativement, pour une authentification JWT personnalisée avec votre propre fournisseur OIDC, utilisez `RuntimeAuthorizerConfiguration.usingJWT()` :

```ts {6-10}
import { MyProjectAgent } from ':my-scope/common-constructs';
import { RuntimeAuthorizerConfiguration } from '@aws-cdk/aws-bedrock-agentcore-alpha';

export class ExampleStack extends Stack {
  constructor(scope: Construct, id: string) {
    new MyProjectAgent(this, 'MyProjectAgent', {
      authorizerConfiguration: RuntimeAuthorizerConfiguration.usingJWT(
        'https://example.com/.well-known/openid-configuration',
        ['client1', 'client2'], // IDs clients autorisés (optionnel)
        ['audience1'],          // Audiences autorisées (optionnel)
      ),
    });
  }
}
```
</Fragment>
<Fragment slot="terraform">
Pour configurer l'authentification JWT, modifiez votre module agent pour configurer la variable `authorizer_configuration` comme suit :

```terraform {18-23}
# packages/common/terraform/src/app/agents/my-project-agent/my-project-agent.tf

data "aws_region" "current" {}

locals {
  aws_region = data.aws_region.current.id

  # Remplacez par vos IDs de user pool/client ou exposez-les comme variables
  user_pool_id = "xxx"
  user_pool_client_ids = ["yyy"]
}

module "agent_core_runtime" {
  source = "../../../core/agent-core"
  agent_runtime_name = "MyProjectAgent"
  docker_image_tag = "my-scope-my-project-agent:latest"
  server_protocol = "HTTP"
  authorizer_configuration = {
    custom_jwt_authorizer = {
      discovery_url = "https://cognito-idp.${local.aws_region}.amazonaws.com/${local.user_pool_id}/.well-known/openid-configuration"
      allowed_clients = local.user_pool_client_ids
    }
  }
  env = var.env
  additional_iam_policy_statements = var.additional_iam_policy_statements
  tags = var.tags
}
```
</Fragment>
</Infrastructure>

### Observabilité

Votre agent est automatiquement configuré avec l'observabilité via [AWS Distro for Open Telemetry](https://aws.amazon.com/otel/) (ADOT), via l'auto-instrumentation dans votre `Dockerfile`.

Vous pouvez trouver les traces dans la console CloudWatch en sélectionnant "GenAI Observability". Notez que pour voir les traces, vous devez activer [Transaction Search](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Transaction-Search.html).

Pour plus de détails, consultez la [documentation AgentCore sur l'observabilité](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/observability-configure.html).

## Invocation de votre agent Strands

### Invoquer le serveur local

Pour invoquer un agent exécuté localement via la cible `<your-agent-name>-serve`, vous pouvez envoyer une simple requête POST à `/invocations` sur le port où votre agent local s'exécute. Par exemple, avec `curl` :

```bash
curl -N -X POST http://localhost:8081/invocations \
  -d '{"prompt": "what is 3 + 5?", "session_id": "abcdefghijklmnopqrstuvwxyz0123456789"}' \
  -H "Content-Type: application/json"
```

:::note
L'argument `-N` donné à `curl` désactive la mise en mémoire tampon du flux de sortie, vous permettant de voir la réponse en streaming en temps réel.
:::

### Invoquer l'agent déployé

<Snippet name="agent/runtime-arn" parentHeading="Invoquer l'agent déployé" />

#### Authentification IAM

Pour l'authentification IAM, la requête doit être signée avec AWS Signature Version 4 (SigV4).

```bash
acurl <region> bedrock-agentcore -N -X POST \
'https://bedrock
-agentcore.<region>.amazonaws.com/runtimes/<url-encoded-arn>/invocations' \
-d '{"prompt": "what is 3 + 5?", "session_id": "abcdefghijklmnopqrstuvwxyz0123456789"}' \
-H 'Content-Type: application/json'
```

<Drawer title="curl avec Sigv4 activé" trigger="Cliquez ici pour plus de détails sur la configuration de la commande acurl ci-dessus">
<Snippet name="tools/acurl" />
</Drawer>

#### Authentification JWT / Cognito

Pour l'authentification Cognito, passez le jeton d'accès Cognito dans l'en-tête `Authorization` :

```bash
curl -N -X POST 'https://bedrock
-agentcore.<region>.amazonaws.com/runtimes/<url-encoded-arn>/invocations' \
  -d '{"prompt": "what is 3 + 5?", "session_id": "abcdefghijklmnopqrstuvwxyz0123456789"}' \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer <access-token>"
```

Vous pouvez obtenir le jeton d'accès en utilisant la commande `cognito-idp admin-initiate-auth` de l'AWS CLI, par exemple :

```bash
aws cognito-idp admin-initiate-auth \
  --user-pool-id <user-pool-id> \
  --client-id <user-pool-client-id> \
  --auth-flow ADMIN_NO_SRP_AUTH \
  --auth-parameters USERNAME=<username>,PASSWORD=<password> \
  --region <region> \
  --query 'AuthenticationResult.AccessToken' \
  --output text
```