---
title: "Serveur Python MCP"
description: "Générer un serveur de Protocole de Contexte de Modèle (MCP) Python pour fournir du contexte aux Modèles de Langage de Grande Taille"
---

import { FileTree } from '@astrojs/starlight/components';
import RunGenerator from '@components/run-generator.astro';
import NxCommands from '@components/nx-commands.astro';
import Link from '@components/link.astro';
import Snippet from '@components/snippet.astro';
import GeneratorParameters from '@components/generator-parameters.astro';

Générez un serveur Python [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) pour fournir du contexte aux Grands Modèles de Langage (LLMs), avec option de déploiement sur [Amazon Bedrock AgentCore](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/).

## Qu'est-ce que le MCP ?

Le [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) est un standard ouvert permettant aux assistants IA d'interagir avec des outils et ressources externes. Il fournit une méthode cohérente pour que les LLMs puissent :

- Exécuter des outils (fonctions) réalisant des actions ou récupérant des informations
- Accéder à des ressources fournissant du contexte ou des données

## Utilisation

### Générer un serveur MCP

Vous pouvez générer un serveur MCP Python de deux façons :

<RunGenerator generator="py#mcp-server" />

:::tip
Utilisez d'abord le <Link path="/guides/python-project">`py#project`</Link> pour créer un projet avant d'y ajouter votre serveur MCP.
:::

### Options

<GeneratorParameters generator="py#mcp-server" />

## Résultat du générateur

Le générateur ajoutera les fichiers suivants à votre projet Python existant :

<FileTree>
  - your-project/
    - your_module/
      - mcp_server/ (ou nom personnalisé si spécifié)
        - \_\_init\_\_.py Initialisation du package Python
        - server.py Définition principale du serveur avec outils et ressources d'exemple
        - stdio.py Point d'entrée pour le transport STDIO, utile pour les serveurs MCP locaux simples
        - http.py Point d'entrée pour le transport HTTP Streamable, utile pour l'hébergement du serveur MCP
        - Dockerfile Point d'entrée pour l'hébergement du serveur MCP (exclu si `computeType` est `None`)
    - pyproject.toml Mis à jour avec les dépendances MCP
    - project.json Mis à jour avec les cibles de service du serveur MCP
</FileTree>

### Infrastructure

:::note
Si vous avez sélectionné `None` pour `computeType`, le générateur ne fournira aucune infrastructure-as-code.
:::

<Snippet name="shared-constructs" />

<Snippet name="mcp/shared-constructs" />

## Utilisation de votre serveur MCP

### Ajout d'outils

Les outils sont des fonctions que l'assistant IA peut appeler pour effectuer des actions. Le serveur MCP Python utilise la bibliothèque [MCP Python SDK (FastMCP)](https://github.com/modelcontextprotocol/python-sdk) qui propose une approche basée sur des décorateurs pour définir des outils.

Vous pouvez ajouter de nouveaux outils dans le fichier `server.py` :

```python
@mcp.tool(description="Description de votre outil")
def your_tool_name(param1: str, param2: int) -> str:
    """Implémentation de l'outil avec annotations de type"""
    # Logique de l'outil ici
    return f"Résultat : {param1} avec {param2}"
```

La bibliothèque FastMCP gère automatiquement :
- La validation des types selon les annotations de votre fonction
- La génération du schéma JSON pour le protocole MCP
- La gestion des erreurs et le formatage des réponses

### Ajout de ressources

Les ressources fournissent du contexte à l'assistant IA. Vous pouvez les ajouter avec le décorateur `@mcp.resource` :

```python
@mcp.resource("example://static-resource", description="Exemple de ressource statique")
def static_resource() -> str:
    """Retourne un contenu statique"""
    return "Ce contenu statique fournit du contexte à l'IA"

@mcp.resource("dynamic://resource/{item_id}", description="Exemple de ressource dynamique")
def dynamic_resource(item_id: str) -> str:
    """Retourne un contenu dynamique basé sur des paramètres"""
    # Récupération des données selon item_id
    data = fetch_data_for_item(item_id)
    return f"Contenu dynamique pour {item_id} : {data}"
```

## Configuration avec les assistants IA

<Snippet name="mcp/configuration-py" parentHeading="Configuration avec les assistants IA" />

## Exécution de votre serveur MCP

### Inspector

Le générateur configure une cible nommée `<your-server-name>-inspect` qui lance l'[MCP Inspector](https://github.com/modelcontextprotocol/inspector) avec la configuration pour se connecter à votre serveur MCP via le transport STDIO.

<NxCommands commands={['run your-project:your-server-name-inspect']} />

Ceci démarre l'inspector sur `http://localhost:6274`. Cliquez sur le bouton "Connect" pour commencer.

### STDIO

La méthode la plus simple pour tester et utiliser un serveur MCP est d'utiliser l'inspector ou de le configurer avec un assistant IA (comme ci-dessus).

Vous pouvez cependant exécuter votre serveur avec le [transport STDIO](https://modelcontextprotocol.io/docs/concepts/transports#standard-input%2Foutput-stdio) directement via la cible `<your-server-name>-serve-stdio`.

<NxCommands commands={['run your-project:your-server-name-serve-stdio']} />

Cette commande utilise `uv run` pour exécuter votre serveur MCP avec le transport STDIO.

### HTTP Streamable

Pour exécuter votre serveur MCP localement avec le [transport HTTP Streamable](https://modelcontextprotocol.io/docs/concepts/transports#streamable-http), utilisez la cible `<your-server-name>-serve`.

<NxCommands commands={['run your-project:your-server-name-serve']} />

Cette commande utilise `uv run` pour exécuter votre serveur MCP avec le transport HTTP, généralement sur le port 8000.

## Déploiement sur Bedrock AgentCore Runtime

<Snippet name="mcp/bedrock-deployment" parentHeading="Déploiement sur Bedrock AgentCore Runtime" />

### Cibles Bundle et Docker

Pour construire votre serveur MCP pour Bedrock AgentCore Runtime, une cible `bundle` est ajoutée à votre projet. Elle :

- Exporte vos dépendances Python dans un fichier `requirements.txt` via `uv export`
- Installe les dépendances pour la plateforme cible (`aarch64-manylinux2014`) via `uv pip install`

Une cible `docker` spécifique à votre serveur MCP est aussi ajoutée. Elle :

- Construit une image Docker depuis le `Dockerfile` exécutant votre serveur MCP sur le port `8000`, conformément au [contrat de service MCP](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/runtime-service-contract.html#mcp-protocol-contract)

:::tip
L'image Docker est construite avec un tag (ex: `my-scope-my-project-mcp-server:latest`), référencé par votre infrastructure CDK/Terraform, permettant à votre `Dockerfile` de rester colocalisé avec votre projet de serveur MCP.
:::

### Observabilité

<Snippet name="mcp/observability" parentHeading="Observabilité" />