---
title: "Jogo de Dungeons com IA"
description: "Um guia passo a passo de como construir um jogo de aventura de dungeon com IA usando o @aws/nx-plugin."
---



import { Aside, Code, FileTree, Steps, Tabs, TabItem } from '@astrojs/starlight/components';
import { Image } from 'astro:assets';
import Drawer from '@components/drawer.astro';
import Link from '@components/link.astro';
import RunGenerator from '@components/run-generator.astro';
import NxCommands from '@components/nx-commands.astro';
import InstallCommand from '@components/install-command.astro';
import dungeonAdventureArchitecturePng from '@assets/dungeon-game-architecture.png'
import dungeonAdventureErPng from '@assets/dungeon-adventure-er.png'
import baselineWebsitePng from '@assets/baseline-website.png'
import baselineGamePng from '@assets/baseline-game.png'
import nxGraphPng from '@assets/nx-graph.png'
import gameSelectPng from '@assets/game-select.png'
import gameConversationPng from '@assets/game-conversation.png'

## Módulo 3: Implementação da API de História

<Aside type="caution">
Certifique-se de ter concedido acesso ao modelo **Anthropic Claude 3.5 Sonnet v2** seguindo os passos descritos em [este guia](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access-modify.html).
</Aside>

A StoryApi consiste em uma única API `generate_story` que, dado um `Game` e uma lista de `Action`s como contexto, irá progredir uma história. Esta API será implementada como uma API de streaming em Python/FastAPI e também demonstrará como fazer ajustes no código gerado para adequá-lo ao propósito.

### Implementação da API

Para criar nossa API, primeiro precisamos instalar algumas dependências adicionais:

- `boto3` será usado para chamar o Amazon Bedrock;
- `uvicorn` será usado para iniciar nossa API em conjunto com o [Lambda Web Adapter (LWA)](https://github.com/awslabs/aws-lambda-web-adapter);
- `copyfiles` é uma dependência npm necessária para suportar a cópia multiplataforma de arquivos ao atualizar nossa tarefa `bundle`.

Para instalar estas dependências, execute os seguintes comandos:

<NxCommands commands={["run dungeon_adventure.story_api:add --args boto3 uvicorn"]} />
<InstallCommand pkg="copyfiles" dev />

Agora vamos substituir o conteúdo dos seguintes arquivos em `packages/story_api/story_api`:

<Tabs>
<TabItem label="main.py">
```python
// packages/story_api/story_api/main.py
import json

from boto3 import client
from fastapi.responses import PlainTextResponse, StreamingResponse
from pydantic import BaseModel

from .init import app, lambda_handler

handler = lambda_handler

bedrock = client('bedrock-runtime')

class Action(BaseModel):
    role: str
    content: str

class StoryRequest(BaseModel):
    genre: str
    playerName: str
    actions: list[Action]

async def bedrock_stream(request: StoryRequest):
    messages = [
        {"role": "user", "content": "Continue or create a new story..."}
    ]

    for action in request.actions:
        messages.append({"role": action.role, "content": action.content})

    response = bedrock.invoke_model_with_response_stream(
        modelId='anthropic.claude-3-sonnet-20240229-v1:0',
        body=json.dumps({
            "system":f"""
            You are running an AI text adventure game in the {request.genre} genre.
            Player: {request.playerName}. Return less than 200 characters of text.
            """,
            "messages": messages,
            "max_tokens": 1000,
            "temperature": 0.7,
            "anthropic_version": "bedrock-2023-05-31"
        })
    )

    stream = response.get('body')
    if stream:
        for event in stream:
            chunk = event.get('chunk')
            if chunk:
                message = json.loads(chunk.get("bytes").decode())
                if message['type'] == "content_block_delta":
                    yield message['delta']['text'] or ""
                elif message['type'] == "message_stop":
                    yield "\n"

@app.post("/story/generate",
          openapi_extra={'x-streaming': True},
          response_class=PlainTextResponse)
def generate_story(request: StoryRequest) -> str:
    return StreamingResponse(bedrock_stream(request), media_type="text/plain")
```
</TabItem>
<TabItem label="init.py">
```python
// packages/story_api/story_api/init.py
import os
import uuid
from collections.abc import Callable

from aws_lambda_powertools import Logger, Metrics, Tracer
from aws_lambda_powertools.metrics import MetricUnit
from fastapi import FastAPI, Request, Response
from fastapi.openapi.utils import get_openapi
from fastapi.responses import JSONResponse
from fastapi.routing import APIRoute
from mangum import Mangum
from pydantic import BaseModel
from starlette.middleware.exceptions import ExceptionMiddleware

os.environ["POWERTOOLS_METRICS_NAMESPACE"] = "StoryApi"
os.environ["POWERTOOLS_SERVICE_NAME"] = "StoryApi"

logger: Logger = Logger()
metrics: Metrics = Metrics()
tracer: Tracer = Tracer()

class InternalServerErrorDetails(BaseModel):
    detail: str

app = FastAPI(
    title="StoryApi",
    responses={
        500: {"model": InternalServerErrorDetails}
    }
)
lambda_handler = Mangum(app)

# Add tracing
lambda_handler.__name__ = "handler"  # tracer requires __name__ to be set
lambda_handler = tracer.capture_lambda_handler(lambda_handler)
# Add logging
lambda_handler = logger.inject_lambda_context(lambda_handler, clear_state=True)
# Add metrics last to properly flush metrics.
lambda_handler = metrics.log_metrics(lambda_handler, capture_cold_start_metric=True)

# Add exception middleware(s)
app.add_middleware(ExceptionMiddleware, handlers=app.exception_handlers)

@app.exception_handler(Exception)
async def unhandled_exception_handler(request, err):
    logger.exception("Unhandled exception")

    metrics.add_metric(name="Failure", unit=MetricUnit.Count, value=1)

    return JSONResponse(status_code=500,
                        content=InternalServerErrorDetails(
                            detail="Internal Server Error").model_dump())

@app.middleware("http")
async def metrics_handler(request: Request, call_next):
    metrics.add_dimension("route", f"{request.method} {request.url.path}")
    metrics.add_metric(name="RequestCount", unit=MetricUnit.Count, value=1)

    response = await call_next(request)

    if response.status_code == 200:
        metrics.add_metric(name="Success", unit=MetricUnit.Count, value=1)

    return response

# Add correlation id middleware
@app.middleware("http")
async def add_correlation_id(request: Request, call_next):
    # Get correlation id from X-Correlation-Id header
    corr_id = request.headers.get("x-correlation-id")
    if not corr_id and "aws.context" in request.scope:
        # If empty, use request id from aws context
        corr_id = request.scope["aws.context"].aws_request_id
    elif not corr_id:
        # If still empty, use uuid
        corr_id = uuid.uuid4().hex

    # Add correlation id to logs
    logger.set_correlation_id(corr_id)

    response = await call_next(request)

    # Return correlation header in response
    response.headers["X-Correlation-Id"] = corr_id
    return response

class LoggerRouteHandler(APIRoute):
    def get_route_handler(self) -> Callable:
        original_route_handler = super().get_route_handler()

        async def route_handler(request: Request) -> Response:
            # Add fastapi context to logs
            ctx = {
                "path": request.url.path,
                "route": self.path,
                "method": request.method,
            }
            logger.append_keys(fastapi=ctx)
            logger.info("Received request")

            return await original_route_handler(request)

        return route_handler

app.router.route_class = LoggerRouteHandler

def custom_openapi():
    if app.openapi_schema:
        return app.openapi_schema
    for route in app.routes:
        if isinstance(route, APIRoute):
            route.operation_id = route.name
    openapi_schema = get_openapi(
        title=app.title,
        version=app.version,
        openapi_version=app.openapi_version,
        description=app.description,
        routes=app.routes,
    )
    app.openapi_schema = openapi_schema
    return app.openapi_schema

app.openapi = custom_openapi

```

:::note
A alteração acima em `init.py` simplesmente remove o middleware CORS para evitar conflitos com o próprio tratamento de cabeçalhos CORS do Lambda Function URL.
:::

</TabItem>
</Tabs>

Analisando o código acima:

- Usamos a configuração `x-streaming` para indicar que esta é uma API de streaming quando gerarmos nosso client SDK. Isso permitirá consumir esta API de forma streaming mantendo a segurança de tipos!
- Nossa API simplesmente retorna um fluxo de texto conforme definido por `media_type="text/plain"` e `response_class=PlainTextResponse`

:::note
Toda vez que você fizer alterações no FastAPI, precisará reconstruir seu projeto para ver essas alterações refletidas no client gerado em seu website.

Faremos mais algumas alterações abaixo antes de reconstruir.
:::

### Infraestrutura

A <Link path="get_started/tutorials/dungeon-game/1#game-ui-infrastructure">infraestrutura configurada anteriormente</Link> assume que todas as APIs têm um API Gateway integrado com funções Lambda. Para nossa `story_api`, não queremos usar o API Gateway pois ele não suporta respostas streaming. Em vez disso, usaremos um [Lambda Function URL configurado com response streaming](https://docs.aws.amazon.com/lambda/latest/dg/configuration-response-streaming.html).

Para suportar isso, primeiro atualizaremos nossos constructs CDK da seguinte forma:

<Tabs>
<TabItem label="story-api.ts">
```ts
// packages/common/constructs/src/app/apis/story-api.ts
import { Duration, Stack, CfnOutput } from 'aws-cdk-lib';
import { IGrantable, Grant } from 'aws-cdk-lib/aws-iam';
import {
  Runtime,
  Code,
  Tracing,
  LayerVersion,
  FunctionUrlAuthType,
  InvokeMode,
  Function,
} from 'aws-cdk-lib/aws-lambda';
import { Construct } from 'constructs';
import url from 'url';
import { RuntimeConfig } from '../../core/runtime-config.js';

export class StoryApi extends Construct {
  public readonly handler: Function;

  constructor(scope: Construct, id: string) {
    super(scope, id);

    this.handler = new Function(this, 'Handler', {
      runtime: Runtime.PYTHON_3_12,
      handler: 'run.sh',
      code: Code.fromAsset(
        url.fileURLToPath(
          new URL(
            '../../../../../../dist/packages/story_api/bundle',
            import.meta.url,
          ),
        ),
      ),
      timeout: Duration.seconds(30),
      tracing: Tracing.ACTIVE,
      environment: {
        AWS_CONNECTION_REUSE_ENABLED: '1',
      },
    });

    const stack = Stack.of(this);
    this.handler.addLayers(
      LayerVersion.fromLayerVersionArn(
        this,
        'LWALayer',
        `arn:aws:lambda:${stack.region}:753240598075:layer:LambdaAdapterLayerX86:24`,
      ),
    );
    this.handler.addEnvironment('PORT', '8000');
    this.handler.addEnvironment('AWS_LWA_INVOKE_MODE', 'response_stream');
    this.handler.addEnvironment('AWS_LAMBDA_EXEC_WRAPPER', '/opt/bootstrap');
    const functionUrl = this.handler.addFunctionUrl({
      authType: FunctionUrlAuthType.AWS_IAM,
      invokeMode: InvokeMode.RESPONSE_STREAM,
      cors: {
        allowedOrigins: ['*'],
        allowedHeaders: [
          'authorization',
          'content-type',
          'x-amz-content-sha256',
          'x-amz-date',
          'x-amz-security-token',
        ],
      },
    });

    new CfnOutput(this, 'StoryApiUrl', { value: functionUrl.url });

    // Register the API URL in runtime configuration for client discovery
    RuntimeConfig.ensure(this).config.apis = {
      ...RuntimeConfig.ensure(this).config.apis!,
      StoryApi: functionUrl.url,
    };
  }

  public grantInvokeAccess(grantee: IGrantable) {
    Grant.addToPrincipal({
      grantee,
      actions: ['lambda:InvokeFunctionUrl'],
      resourceArns: [this.handler.functionArn],
      conditions: {
        StringEquals: {
          'lambda:FunctionUrlAuthType': 'AWS_IAM',
        },
      },
    });
  }
}

```
</TabItem>
<TabItem label="application-stack.ts">
```diff lang="typescript"
// packages/infra/src/stacks/application-stack.ts
import {
  GameApi,
  GameUI,
  StoryApi,
  UserIdentity,
} from ':dungeon-adventure/common-constructs';
import * as cdk from 'aws-cdk-lib';
import { Construct } from 'constructs';
import { ElectrodbDynamoTable } from '../constructs/electrodb-table.js';
+import { PolicyStatement, Effect } from 'aws-cdk-lib/aws-iam';

export class ApplicationStack extends cdk.Stack {
  constructor(scope: Construct, id: string, props?: cdk.StackProps) {
    super(scope, id, props);

    // The code that defines your stack goes here
    const userIdentity = new UserIdentity(this, 'UserIdentity');

    const electroDbTable = new ElectrodbDynamoTable(this, 'ElectroDbTable');

    const gameApi = new GameApi(this, 'GameApi', {
      integrations: GameApi.defaultIntegrations(this)
        .withDefaultOptions({
          environment: {
            TABLE_NAME: electroDbTable.tableName,
          },
        })
        .build(),
    });

    // Grant read/write access to each handler depending on the permissions it requires
    electroDbTable.grantReadData(gameApi.integrations['actions.query'].handler);
    electroDbTable.grantReadData(gameApi.integrations['games.query'].handler);
    electroDbTable.grantReadWriteData(
      gameApi.integrations['actions.save'].handler,
    );
    electroDbTable.grantReadWriteData(
      gameApi.integrations['games.save'].handler,
    );

-    const storyApi = new StoryApi(this, 'StoryApi', {
-      integrations: StoryApi.defaultIntegrations(this).build(),
-    });
+    const storyApi = new StoryApi(this, 'StoryApi');
+    storyApi.handler.addToRolePolicy(
+      new PolicyStatement({
+        effect: Effect.ALLOW,
+        actions: ['bedrock:InvokeModelWithResponseStream'],
+        resources: [
+          'arn:aws:bedrock:*::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0',
+        ],
+      }),
+    );

    // grant our authenticated role access to invoke our APIs
    [storyApi, gameApi].forEach((api) =>
      api.grantInvokeAccess(userIdentity.identityPool.authenticatedRole),
    );

    // Ensure this is instantiated last so our runtime-config.json can be automatically configured
    new GameUI(this, 'GameUI');
  }
}

```
</TabItem>
</Tabs>

Agora atualizaremos o `story_api` para suportar a implantação do [Lambda Web Adapter](https://github.com/awslabs/aws-lambda-web-adapter).

<Tabs>
<TabItem label="run.sh">
```bash
// packages/story_api/run.sh
#!/bin/bash

PATH=$PATH:$LAMBDA_TASK_ROOT/bin \
    PYTHONPATH=$PYTHONPATH:/opt/python:$LAMBDA_RUNTIME_DIR \
    exec python -m uvicorn --port=$PORT story_api.main:app
```
</TabItem>
<TabItem label="project.json">
```diff lang="json"
// packages/story_api/project.json
{
  "name": "dungeon_adventure.story_api",
  "$schema": "../../node_modules/nx/schemas/project-schema.json",
  "projectType": "application",
  "sourceRoot": "packages/story_api/story_api",
  "targets": {
    ...
    "bundle": {
      "cache": true,
      "executor": "nx:run-commands",
      "outputs": ["{workspaceRoot}/dist/packages/story_api/bundle"],
      "options": {
        "commands": [
          "uv export --frozen --no-dev --no-editable --project story_api -o dist/packages/story_api/bundle/requirements.txt",
          "uv pip install -n --no-installer-metadata --no-compile-bytecode --python-platform x86_64-manylinux2014 --python `uv python pin` --target dist/packages/story_api/bundle -r dist/packages/story_api/bundle/requirements.txt",
+          "copyfiles -f packages/story_api/run.sh dist/packages/story_api/bundle"
        ],
        "parallel": false
      },
      "dependsOn": ["compile"]
    },
    ...
  }
}
```
</TabItem>
</Tabs>

### Implantação e testes

Primeiro, vamos construir a base de código:

<NxCommands commands={['run-many --target build --all']} />

<Aside type="tip">
Se encontrar erros de lint, execute o seguinte comando para corrigi-los automaticamente:

<NxCommands commands={['run-many --target lint --configuration=fix --all']} />
</Aside>

Sua aplicação agora pode ser implantada executando o seguinte comando:

<NxCommands commands={['run @dungeon-adventure/infra:deploy dungeon-adventure-infra-sandbox']} />

Esta implantação levará aproximadamente 2 minutos para ser concluída.

<Drawer title="Comando de implantação" trigger="Você também pode implantar todas as stacks de uma vez. Clique aqui para mais detalhes.">

Você também pode implantar todas as stacks contidas na aplicação CDK executando:

<NxCommands commands={['run @dungeon-adventure/infra:deploy --all']} />

Isso **não é recomendado** pois você pode optar por separar seus estágios de implantação em stacks diferentes `ex: infra-prod`. Neste caso, a flag `--all` tentará implantar todas as stacks, o que pode resultar em implantações indesejadas!

</Drawer>

Após a conclusão da implantação, você verá algumas saídas semelhantes às seguintes _(alguns valores foram omitidos)_:

```bash
dungeon-adventure-infra-sandbox
dungeon-adventure-infra-sandbox: deploying... [2/2]

 ✅  dungeon-adventure-infra-sandbox

✨  Deployment time: 354s

Outputs:
dungeon-adventure-infra-sandbox.ElectroDbTableTableNameXXX = dungeon-adventure-infra-sandbox-ElectroDbTableXXX-YYY
dungeon-adventure-infra-sandbox.GameApiEndpointXXX = https://xxx.execute-api.region.amazonaws.com/prod/
dungeon-adventure-infra-sandbox.GameUIDistributionDomainNameXXX = xxx.cloudfront.net
dungeon-adventure-infra-sandbox.StoryApiStoryApiUrlXXX = https://xxx.lambda-url.ap-southeast-2.on.aws/
dungeon-adventure-infra-sandbox.UserIdentityUserIdentityIdentityPoolIdXXX = region:xxx
dungeon-adventure-infra-sandbox.UserIdentityUserIdentityUserPoolIdXXX = region_xxx
```

Podemos testar nossa API de duas formas:
<ul>
<li>Iniciando uma instância local do servidor FastAPI e invocando as APIs usando `curl`</li>
<li>
<Drawer title="Curl com Sigv4 habilitado" trigger="Chamando a API implantada diretamente usando curl com Sigv4">
Você pode adicionar o seguinte script ao seu arquivo `.bashrc` (e executar `source`) ou simplesmente colar o seguinte no mesmo terminal onde deseja executar o comando.
```bash
// ~/.bashrc
acurl () {
    REGION=$1
    SERVICE=$2
    shift; shift;
    curl --aws-sigv4 "aws:amz:$REGION:$SERVICE" --user "$(aws configure get aws_access_key_id):$(aws configure get aws_secret_access_key)" -H "X-Amz-Security-Token: $(aws configure get aws_session_token)" "$@"
}
```

Para fazer uma requisição curl autenticada com Sigv4, você pode invocar `acurl` conforme os exemplos:

###### API Gateway
```bash
acurl ap-southeast-2 execute-api -X GET https://xxx
```

###### Lambda function url com streaming
```bash
acurl ap-southeast-2 lambda -N -X POST https://xxx
```
</Drawer>
</li>
</ul>

<Tabs>
  <TabItem label="Local">
  Inicie seu servidor FastAPI local executando:
    <NxCommands commands={["run dungeon_adventure.story_api:serve"]} />

    Após iniciar o servidor FastAPI, chame-o executando:

    ```bash
    curl -N -X POST http://127.0.0.1:8000/story/generate \
      -d '{"genre":"superhero", "actions":[], "playerName":"UnnamedHero"}' \
      -H "Content-Type: application/json"
    ```
  </TabItem>
  <TabItem label="Implantado">
```bash "https://xxx.lambda-url.ap-southeast-2.on.aws/" "ap-southeast-2"
acurl ap-southeast-2 lambda -N -X POST \
  https://xxx.lambda-url.ap-southeast-2.on.aws/story/generate \
  -d '{"genre":"superhero", "actions":[], "playerName":"UnnamedHero"}' \
  -H "Content-Type: application/json"
```
    <Aside type="caution">
    Use o valor de saída `dungeon-adventure-infra-sandbox.StoryApiStoryApiUrlXXX` do CDK deploy para substituir o placeholder de URL destacado e ajuste a região conforme necessário.
    </Aside>
  </TabItem>
</Tabs>

Se o comando for executado com sucesso, você verá uma resposta em streaming similar a:

```
UnnamedHero stood tall, his cape billowing in the wind....
```

Parabéns. Você construiu e implantou sua primeira API usando FastAPI! 🎉🎉🎉