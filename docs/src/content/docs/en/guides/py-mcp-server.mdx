---
title: Python MCP Server
description: Generate a Python Model Context Protocol (MCP) server for providing context to Large Language Models
---

import { FileTree } from '@astrojs/starlight/components';
import RunGenerator from '@components/run-generator.astro';
import NxCommands from '@components/nx-commands.astro';
import Link from '@components/link.astro';
import Snippet from '@components/snippet.astro';
import GeneratorParameters from '@components/generator-parameters.astro';

Generate a Python [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) server for providing context to Large Language Models (LLMs), and optionally deploy it to [Amazon Bedrock AgentCore](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/).

## What is MCP?

The [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) is an open standard that allows AI assistants to interact with external tools and resources. It provides a consistent way for LLMs to:

- Execute tools (functions) that perform actions or retrieve information
- Access resources that provide context or data

## Usage

### Generate an MCP Server

You can generate a Python MCP server in two ways:

<RunGenerator generator="py#mcp-server" />

:::tip
First use the <Link path="/guides/python-project">`py#project`</Link> generator to create a project to add your MCP server to.
:::

### Options

<GeneratorParameters generator="py#mcp-server" />

## Generator Output

The generator will add the following files to your existing Python project:

<FileTree>
  - your-project/
    - your_module/
      - mcp_server/ (or custom name if specified)
        - \_\_init\_\_.py Python package initialization
        - server.py Main server definition with sample tools and resources
        - stdio.py Entry point for STDIO transport, useful for simple local MCP servers
        - http.py Entry point for Streamable HTTP transport, useful for hosting your MCP server
        - Dockerfile Entry point for hosting your MCP server (excluded when `computeType` is set to `None`)
    - pyproject.toml Updated with MCP dependencies
    - project.json Updated with MCP server serve targets
</FileTree>

:::note
Unless you selected `None` for `computeType`, the generator will also create the CDK or Terraform infrastructure to deploy your MCP Server.
:::

## Working with Your MCP Server

### Adding Tools

Tools are functions that the AI assistant can call to perform actions. The Python MCP server uses the [MCP Python SDK (FastMCP)](https://github.com/modelcontextprotocol/python-sdk) library, which provides a simple decorator-based approach for defining tools.

You can add new tools in the `server.py` file:

```python
@mcp.tool(description="Your tool description")
def your_tool_name(param1: str, param2: int) -> str:
    """Tool implementation with type hints"""
    # Your tool logic here
    return f"Result: {param1} with {param2}"
```

The FastMCP library automatically handles:
- Type validation based on your function's type hints
- JSON schema generation for the MCP protocol
- Error handling and response formatting

### Adding Resources

Resources provide context to the AI assistant. You can add resources using the `@mcp.resource` decorator:

```python
@mcp.resource("example://static-resource", description="Static resource example")
def static_resource() -> str:
    """Return static content"""
    return "This is static content that provides context to the AI"

@mcp.resource("dynamic://resource/{item_id}", description="Dynamic resource example")
def dynamic_resource(item_id: str) -> str:
    """Return dynamic content based on parameters"""
    # Fetch data based on item_id
    data = fetch_data_for_item(item_id)
    return f"Dynamic content for {item_id}: {data}"
```

## Configuring with AI Assistants

<Snippet name="mcp/configuration-py" parentHeading="Configuring with AI Assistants" />

## Running Your MCP Server

### Inspector

The generator configures a target named `<your-server-name>-inspect`, which starts the [MCP Inspector](https://github.com/modelcontextprotocol/inspector) with the configuration to connect to your MCP server using STDIO transport.

<NxCommands commands={['run your-project:your-server-name-inspect']} />

This will start the inspector at `http://localhost:6274`. Get started by clicking on the "Connect" button.

### STDIO

The easiest way to test and use an MCP server is by using the inspector or configuring it with an AI assistant (as above).

You can however run your server with [STDIO transport](https://modelcontextprotocol.io/docs/concepts/transports#standard-input%2Foutput-stdio) directly using the `<your-server-name>-serve-stdio` target.

<NxCommands commands={['run your-project:your-server-name-serve-stdio']} />

This command uses `uv run` to execute your MCP server with STDIO transport.

### Streamable HTTP

If you would like to run your MCP server locally using [Streamable HTTP transport](https://modelcontextprotocol.io/docs/concepts/transports#streamable-http), you can use the `<your-server-name>-serve-http` target.

<NxCommands commands={['run your-project:your-server-name-serve-http']} />

This command uses `uv run` to execute your MCP server with HTTP transport, typically running on port 8000.

## Deploying Your MCP Server to Bedrock AgentCore Runtime

<Snippet name="mcp/bedrock-deployment" parentHeading="Deploying Your MCP Server to Bedrock AgentCore Runtime" />

### Bundle and Docker Targets

In order to build your MCP server for Bedrock AgentCore Runtime, a `bundle` target is added to your project, which:

- Exports your Python dependencies to a `requirements.txt` file using `uv export`
- Installs dependencies for the target platform (`aarch64-manylinux2014`) using `uv pip install`

A `docker` target specific to your MCP server is also added, which:

- Builds a docker image from the `Dockerfile` which runs your MCP server on port `8000`, as per the [MCP protocol contract](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/runtime-service-contract.html#mcp-protocol-contract)

:::tip
The docker image is built using a tag (for example `my-scope-my-project-mcp-server:latest`), which is referenced by your CDK or Terraform infrastructure, allowing for your `Dockerfile` to be co-located with your MCP server project.
:::

### Observability

<Snippet name="mcp/observability" parentHeading="Observability" />
