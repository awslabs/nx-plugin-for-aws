---
title: TypeScript MCP Server
description: Generate a TypeScript Model Context Protocol (MCP) server for providing context to Large Language Models
---

import { FileTree } from '@astrojs/starlight/components';
import RunGenerator from '@components/run-generator.astro';
import NxCommands from '@components/nx-commands.astro';
import Link from '@components/link.astro';
import Snippet from '@components/snippet.astro';
import GeneratorParameters from '@components/generator-parameters.astro';

Generate a TypeScript [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) server for providing context to Large Language Models (LLMs).

## What is MCP?

The [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) is an open standard that allows AI assistants to interact with external tools and resources. It provides a consistent way for LLMs to:

- Execute tools (functions) that perform actions or retrieve information
- Access resources that provide context or data

## Usage

### Generate an MCP Server

You can generate a TypeScript MCP server in two ways:

<RunGenerator generator="ts#mcp-server" />

:::tip
First use the <Link path="/guides/typescript-project">`ts#project`</Link> generator to create a project to add your MCP server to.
:::

### Options

<GeneratorParameters generator="ts#mcp-server" />

## Generator Output

The generator will add the following files to your existing TypeScript project:

<FileTree>
  - your-project/
    - src/
      - mcp-server/ (or custom name if specified)
        - index.ts Entry point for the MCP server
        - server.ts Main server definition
        - tools/
          - add.ts Sample tool
        - resources/
          - sample-guidance.ts Sample resource
    - package.json Updated with bin entry and MCP dependencies
    - project.json Updated with MCP server serve target
</FileTree>

## Working with Your MCP Server

### Adding Tools

Tools are functions that the AI assistant can call to perform actions. You can add new tools in the `server.ts` file:

```typescript
server.tool("toolName", "tool description",
  { param1: z.string(), param2: z.number() }, // Input schema using Zod
  async ({ param1, param2 }) => {
    // Tool implementation
    return {
      content: [{ type: "text", text: "Result" }]
    };
  }
);
```

### Adding Resources

Resources provide context to the AI assistant. You can add static resources from files or dynamic resources:

```typescript
const exampleContext = 'some context to return';

server.resource('resource-name', 'example://resource', async (uri) => ({
  contents: [{ uri: uri.href, text: exampleContext }],
}));

// Dynamic resource
server.resource('dynamic-resource', 'dynamic://resource', async (uri) => {
  const data = await fetchSomeData();
  return {
    contents: [{ uri: uri.href, text: data }],
  };
});
```

## Configuring with AI Assistants

### Configuration Files

Most AI assistants that support MCP use a similar configuration approach. You'll need to create or update a configuration file with your MCP server details:

```json
{
  "mcpServers": {
    "your-mcp-server": {
      "command": "npx",
      "args": ["tsx", "/path/to/your-mcp-server/index.ts"]
    }
  }
}
```

:::caution
If you receive an error such as `ENOENT npx` when connecting to your server, you might need to specify the full path to `npx`, which you can obtain by running `which npx` in your terminal.
:::

### Hot Reload

While developing your MCP server, you may wish to configure the `--watch` flag so that the AI assistant always sees the latest versions of tools/resources:

```json {5}
{
  "mcpServers": {
    "your-mcp-server": {
      "command": "npx",
      "args": ["tsx", "--watch", "/path/to/your-mcp-server/index.ts"]
    }
  }
}
```

:::note
If you add new tools or resources you may need to refresh your MCP server in the AI assistant.
:::

### Assistant-Specific Configuration

Please refer to the following documentation for configuring MCP with specific AI Assistants:

<Snippet name="mcp/assistant-docs" />

:::tip
Some AI Assistants, such as Amazon Q Developer, allow you to specify workspace level MCP server configuration, which is particularly useful for defining the relevant MCP servers for a particular project.
:::

## Running Your MCP Server

The easiest way to test and use an MCP server is by configuring it with an AI assistant (as above). You can however run the server using the `<your-server-name>-serve` target, which can be useful if you switch from [STDIO transport](https://modelcontextprotocol.io/docs/concepts/transports#standard-input%2Foutput-stdio) to [Streamable HTTP transport](https://modelcontextprotocol.io/docs/concepts/transports#streamable-http).

<NxCommands commands={['run your-project:your-server-name-serve']} />

This command uses `tsx --watch` to automatically restart the server when files change.
