---
title: TypeScript MCP Server
description: Generate a TypeScript Model Context Protocol (MCP) server for providing context to Large Language Models
---

import { FileTree } from '@astrojs/starlight/components';
import RunGenerator from '@components/run-generator.astro';
import NxCommands from '@components/nx-commands.astro';
import Link from '@components/link.astro';
import Snippet from '@components/snippet.astro';
import GeneratorParameters from '@components/generator-parameters.astro';

Generate a TypeScript [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) server for providing context to Large Language Models (LLMs), and optionally deploy it to [Amazon Bedrock AgentCore](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/).

## What is MCP?

The [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) is an open standard that allows AI assistants to interact with external tools and resources. It provides a consistent way for LLMs to:

- Execute tools (functions) that perform actions or retrieve information
- Access resources that provide context or data

## Usage

### Generate an MCP Server

You can generate a TypeScript MCP server in two ways:

<RunGenerator generator="ts#mcp-server" />

:::tip
First use the <Link path="/guides/typescript-project">`ts#project`</Link> generator to create a project to add your MCP server to.
:::

### Options

<GeneratorParameters generator="ts#mcp-server" />

## Generator Output

The generator will add the following files to your existing TypeScript project:

<FileTree>
  - your-project/
    - src/
      - mcp-server/ (or custom name if specified)
        - index.ts Exports your server
        - server.ts Main server definition
        - stdio.ts Entry point for STDIO transport, useful for simple local MCP servers
        - http.ts Entry point for Streamable HTTP transport, useful for hosting your MCP server
        - tools/
          - add.ts Sample tool
        - resources/
          - sample-guidance.ts Sample resource
        - Dockerfile Entry point for hosting your MCP server (excluded when `computeType` is set to `None`)
    - package.json Updated with bin entry and MCP dependencies
    - project.json Updated with MCP server serve target
</FileTree>

### Infrastructure

:::note
If you selected `None` for `computeType`, the generator will not vend any infrastructure as code.
:::

<Snippet name="shared-constructs" />

<Snippet name="mcp/shared-constructs" />

## Working with Your MCP Server

### Adding Tools

Tools are functions that the AI assistant can call to perform actions. You can add new tools in the `server.ts` file:

```typescript
server.registerTool("toolName", {
  description: "tool description",
  inputSchema: { param1: z.string(), param2: z.number() } // Input schema using Zod
},
  async ({ param1, param2 }) => {
    // Tool implementation
    return {
      content: [{ type: "text", text: "Result" }]
    };
  }
);
```

### Adding Resources

Resources provide context to the AI assistant. You can add static resources from files or dynamic resources:

```typescript
const exampleContext = 'some context to return';

server.registerResource('resource-name', 'example://resource', {}, async (uri) => ({
  contents: [{ uri: uri.href, text: exampleContext }],
}));

// Dynamic resource
server.registerResource('dynamic-resource', 'dynamic://resource', {}, async (uri) => {
  const data = await fetchSomeData();
  return {
    contents: [{ uri: uri.href, text: data }],
  };
});
```

## Configuring with AI Assistants

<Snippet name="mcp/configuration-ts" parentHeading="Configuring with AI Assistants" />

## Running Your MCP Server

### Inspector

The generator configures a target named `<your-server-name>-inspect`, which starts the [MCP Inspector](https://github.com/modelcontextprotocol/inspector) with the configuration to connect to your MCP server using STDIO transport.

<NxCommands commands={['run your-project:your-server-name-inspect']} />

This will start the inspector at `http://localhost:6274`. Get started by clicking on the "Connect" button.

### STDIO

The easiest way to test and use an MCP server is by using the inspector or configuring it with an AI assistant (as above).

You can however run your server with [STDIO transport](https://modelcontextprotocol.io/docs/concepts/transports#standard-input%2Foutput-stdio) directly using the `<your-server-name>-serve-stdio` target.

<NxCommands commands={['run your-project:your-server-name-serve-stdio']} />

This command uses `tsx --watch` to automatically restart the server when files change.

### Streamable HTTP

If you would like to run your MCP server locally using [Streamable HTTP transport](https://modelcontextprotocol.io/docs/concepts/transports#streamable-http), you can use the `<your-server-name>-serve` target.

<NxCommands commands={['run your-project:your-server-name-serve']} />

This command uses `tsx --watch` to automatically restart the server when files change.

## Deploying Your MCP Server to Bedrock AgentCore Runtime

<Snippet name="mcp/bedrock-deployment" parentHeading="Deploying Your MCP Server to Bedrock AgentCore Runtime" />

### Bundle Target

<Snippet name="ts-bundle" />

The bundle target uses `http.ts` as the entrypoint for the Streamable HTTP MCP server to host on Bedrock AgentCore Runtime.

### Docker Target

The generator configures a `<your-server-name>-docker` target which runs the bundled Streamable HTTP MCP server on port `8000` as per the [MCP protocol contract](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/runtime-service-contract.html#mcp-protocol-contract).

:::tip
The docker image is built using a tag (for example `my-scope-my-project-mcp-server:latest`), which the CDK construct's `Dockerfile` inherits from, allowing for your `Dockerfile` to be co-located with your MCP server project.
:::

A `docker` target is also generated which runs the docker build for all MCP servers if you have multiple defined.

### Observability

<Snippet name="mcp/observability" parentHeading="Observability" />
