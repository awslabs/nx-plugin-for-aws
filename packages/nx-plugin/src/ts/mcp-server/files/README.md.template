# <%- name %>

This package defines a Model Context Protocol (MCP) Server in TypeScript.

## What is MCP?

The Model Context Protocol (MCP) is a standardized protocol for providing context to Large Language Models (LLMs). It allows AI assistants to access external tools and resources through a consistent interface.

## Documentation

- [Model Context Protocol Documentation](https://modelcontextprotocol.io/)
- [MCP TypeScript SDK Documentation](https://github.com/modelcontextprotocol/sdk-typescript)

## Developer Guide

### Getting Started

This MCP server is built using the MCP TypeScript SDK. Here's how to work with it:

1. **Server Structure**: The main server code is in `src/server.ts`. This file defines the server, its tools, and resources.

2. **Adding Tools**: Tools are functions that the LLM can call to perform actions. Add new tools using the `server.tool()` method:

```typescript
server.tool("toolName",
  { param1: z.string(), param2: z.number() }, // Input schema using Zod
  async ({ param1, param2 }) => {
    // Tool implementation
    return {
      content: [{ type: "text", text: "Result" }]
    };
  }
);
```

3. **Adding Resources**: Resources provide context to the LLM. You can add static resources from files or dynamic resources:

```typescript
// Static resource from a file
import resourceContent from './resources/my-resource.md';

server.resource('resource-name', 'example://resource', async (uri) => ({
  contents: [{ uri: uri.href, text: resourceContent }],
}));

// Dynamic resource
server.resource('dynamic-resource', 'dynamic://resource', async (uri) => {
  const data = await fetchSomeData();
  return {
    contents: [{ uri: uri.href, text: data }],
  };
});
```

### Building the Server

To build the server for use with AI assistants:

```bash
nx run <project-name>:bundle
```

This creates a bundled version of your server in `dist/<project-path>/bundle/index.js`.

## Using with AI Assistants

To use your MCP server with AI assistants, you need to build it first to create the bundle:

```bash
nx run <project-name>:bundle
```

### Configuration

Most AI assistants (Amazon Q Developer CLI, Cline, Cursor, Claude Code, etc.) use a similar configuration approach. You'll need to create or update a configuration file with your MCP server details:

```json
{
  "mcpServers": {
    "<%- name %>": {
      "command": "node",
      "args": [
        "/path/to/workspace/dist/<%- dir %>/bundle/index.js"
      ],
      "transportType": "stdio"
    }
  }
}
```

Replace `/path/to/workspace/dist/<%- dir %>/bundle/index.js` with the actual path to your bundled MCP server.

Note that if you receive an error due to `node` missing (eg `ENOENT node`), you might need to specify the full path to `node` which you can obtain by running `which node`.

### Development Mode

During development, you can use the `dev` target to continuously rebuild the bundle whenever you make changes:

```bash
nx run <project-name>:dev
```

This will watch for changes in your project files and automatically rebuild the bundle.

Whenever you've made changes, you'll need to restart the MCP server in your AI assistant to test it out. The exact process depends on the assistant, but generally:

1. Find your MCP server in the assistant's settings or configuration
2. Look for a "Restart" or "Reload" option
